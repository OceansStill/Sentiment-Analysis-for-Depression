{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version : 1.13.1+cu117\n",
      "Torch Text Version : 0.14.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch\n",
    "import torch.utils.data\n",
    "print(\"PyTorch Version : {}\".format(torch.__version__))\n",
    "import torchtext\n",
    "print(\"Torch Text Version : {}\".format(torchtext.__version__))\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data import to_map_style_dataset\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.is_available()\n",
    "#cuda是否可用；\n",
    "#torch.cuda.device_count()\n",
    "#返回gpu数量；\n",
    "#torch.cuda.get_device_name(0)\n",
    "#返回gpu名字，设备索引默认从0开始；\n",
    "#torch.cuda.current_device()\n",
    "#返回当前设备索引；\n",
    "#nvcc --version\n",
    "#nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.创建分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', ',', 'how', 'are', 'you', '?']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\") ## We'll use tokenizer available from PyTorch\n",
    "\n",
    "tokenizer(\"Hello, How are you?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.导入GloVe词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchtext.vocab as vocab\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "# cache_dir是保存golve词典的缓存路径\n",
    "cache_dir = '.vector_cache/glove.840B.300d'\n",
    "# dim是embedding的维度\n",
    "global_vectors = vocab.GloVe(name='6B', dim=300, cache=cache_dir) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以在线下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom torchtext.vocab import GloVe\\n\\n\\nglobal_vectors = GloVe(name='840B', dim=300)\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "\n",
    "global_vectors = GloVe(name='840B', dim=300)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 300])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = global_vectors.get_vecs_by_tokens(tokenizer(\"Hello, How are you?\"), lower_case_backup=True)\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2559e-01,  1.3630e-02,  1.0306e-01, -1.0123e-01,  9.8128e-02,\n",
       "          1.3627e-01, -1.0721e-01,  2.3697e-01,  3.2870e-01, -1.6785e+00,\n",
       "          2.2393e-01,  1.2409e-01, -8.6708e-02,  3.3010e-01,  3.4375e-01,\n",
       "         -8.7582e-04, -2.9658e-01,  2.4417e-01, -1.1592e-01, -3.5742e-02,\n",
       "         -1.0830e-02,  2.0776e-01,  2.9285e-01, -7.3491e-02, -1.8598e-01,\n",
       "         -2.0090e-01, -9.5366e-02,  6.3732e-03, -1.3620e-01,  9.2028e-02,\n",
       "         -3.9957e-02,  1.9027e-01, -1.0456e-01,  2.7670e-03, -7.1742e-01,\n",
       "         -1.2915e-01, -1.3451e-03,  2.7002e-01, -5.3023e-02,  2.2148e-01,\n",
       "          1.3881e-01, -1.5051e-01, -1.9150e-01,  1.6402e-01,  9.7484e-02,\n",
       "          5.6841e-02,  3.9789e-01,  4.0725e-01,  1.4802e-01,  2.1569e-01,\n",
       "         -1.0671e-01, -1.0232e-01,  2.4810e-02, -2.2100e-01, -1.0720e-02,\n",
       "          1.4234e-01, -2.8242e-01,  1.9254e-01,  8.6720e-02, -3.8970e-01,\n",
       "          1.1321e-01,  1.3779e-03,  6.4009e-03, -1.6206e-01, -8.2153e-02,\n",
       "         -5.5397e-01,  3.6789e-01, -4.0159e-03,  2.0710e-01, -3.7157e-01,\n",
       "          2.5135e-01, -1.9544e-01, -4.7059e-02,  1.7155e-01, -2.4036e-01,\n",
       "         -4.6086e-02,  1.9429e-01, -1.8939e-01, -7.1974e-03,  6.9481e-02,\n",
       "          5.9175e-02, -1.7585e-01,  1.0653e-01,  1.6933e-01, -3.6122e-02,\n",
       "          2.9911e-02, -1.1830e-01,  1.3916e-01, -3.7951e-02,  1.0690e-01,\n",
       "         -2.6069e-01, -1.0307e-01, -1.2272e-01, -1.5032e-01, -4.2409e-02,\n",
       "          1.3354e-02, -2.8510e-01,  1.1248e-02,  1.6073e-01, -1.6384e-01,\n",
       "          2.1233e-01, -1.8476e-01, -9.0874e-04,  6.6687e-02,  1.6918e-01,\n",
       "         -3.5004e-01,  9.9016e-02,  4.6393e-01, -1.9462e-01,  1.0346e-01,\n",
       "         -2.5668e-01, -3.6516e-01, -1.8963e-01, -2.1933e-01,  2.4634e-02,\n",
       "          6.5627e-02, -1.1120e-01, -1.6400e-01,  1.0874e-02, -8.4688e-02,\n",
       "         -1.4923e-01, -7.0223e-02,  2.8887e-02,  8.3497e-02, -1.6193e-02,\n",
       "         -2.4926e-03,  1.7186e-01,  9.8749e-03,  8.0237e-02,  1.4774e-01,\n",
       "          4.3206e-02,  2.7716e-01,  5.7697e-01, -4.1297e-02,  1.2765e-01,\n",
       "         -9.1517e-02,  1.4132e-01,  8.7579e-02,  9.3224e-02,  1.5346e-02,\n",
       "         -1.9856e-01,  1.7277e-02, -1.0708e-01, -1.3059e-02, -3.7227e-01,\n",
       "          7.8568e-02,  1.6677e-01, -1.5359e-01, -3.3294e-01,  3.6986e-02,\n",
       "          1.1697e-01,  3.9781e-02,  3.8464e-02, -1.6247e-01,  4.1280e-01,\n",
       "         -7.7491e-02,  4.5490e-02,  1.1330e-01,  8.2177e-03, -2.5052e-01,\n",
       "          7.0966e-02, -1.1388e-01, -1.1503e-01, -1.1014e-01,  1.0499e-01,\n",
       "          1.5878e-01, -2.7023e-01, -1.1006e-02,  7.6057e-04,  3.3902e-01,\n",
       "          2.5564e-01,  1.6342e-01, -5.6019e-01,  1.3055e-01,  7.6311e-02,\n",
       "         -2.8334e-02,  2.8721e-01, -2.7844e-02, -1.1561e-01,  3.4925e-01,\n",
       "         -1.2420e-01,  2.1405e-01,  2.4116e-01, -3.1343e-02,  1.0913e-01,\n",
       "         -2.4755e-01, -4.5429e-02, -8.2178e-02, -1.8831e-01,  1.8446e-01,\n",
       "         -9.7074e-02,  3.2395e-01,  1.0658e-01, -2.6676e-01, -2.7311e-01,\n",
       "          1.7181e-02,  2.5796e-01, -2.8048e-01,  3.0790e-01, -2.1800e-01,\n",
       "          8.7415e-01, -1.2297e-01,  1.0991e-01, -2.9797e-01,  1.3394e-01,\n",
       "          1.0615e-01, -1.0789e-01, -3.5976e-01, -1.8311e-01, -4.5133e-01,\n",
       "          3.4967e-02, -1.9847e-01,  2.1965e-01,  8.1520e-02,  2.5810e-01,\n",
       "          4.0173e-02,  3.1394e-02,  1.9069e-01,  7.5800e-02, -6.0638e-02,\n",
       "          2.0739e-01,  9.8390e-03, -2.6930e-01,  6.6515e-02, -1.0711e-01,\n",
       "          5.9916e-03,  2.3284e-01, -5.8663e-02,  9.8993e-02, -8.1464e-02,\n",
       "          6.7004e-02, -1.4305e-01,  2.5506e-01, -3.1971e-01, -3.1070e-02,\n",
       "         -9.2451e-02,  2.9440e-01,  2.8947e-01, -5.9804e-02,  2.4286e-01,\n",
       "         -1.6755e-01,  4.2031e-02,  5.1261e-01,  2.4525e-01, -6.5983e-01,\n",
       "          6.2456e-02,  5.2204e-02, -2.5717e-02, -8.0613e-02,  8.0869e-02,\n",
       "          2.2821e-01, -1.0217e-01, -2.0719e-01, -1.2123e-02,  3.4916e-01,\n",
       "          8.6527e-02,  6.6288e-02, -9.9828e-02,  2.5843e-01,  1.1943e-01,\n",
       "         -1.3667e-01, -4.3962e-01,  2.3704e-01,  3.1296e-02,  7.4701e-02,\n",
       "         -2.2387e-01,  7.8162e-03, -1.9016e-01,  4.4444e-02,  2.0191e-01,\n",
       "         -2.0814e-01, -2.8382e-01,  1.0427e-01, -2.1098e-01,  1.8865e-01,\n",
       "          3.1659e-01, -2.0753e+00, -7.1045e-02,  5.2419e-01,  5.6023e-02,\n",
       "         -2.5295e-01, -6.2168e-02, -1.0989e-01, -3.5755e-01, -7.9244e-02,\n",
       "          3.7472e-01, -2.8353e-01,  1.6337e-01,  1.1165e-01, -9.8002e-02,\n",
       "          6.0148e-02, -1.5619e-01, -1.1949e-01,  2.3445e-01,  8.1367e-02,\n",
       "          2.4618e-01, -1.5242e-01, -3.4224e-01, -2.2394e-02,  1.3684e-01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_vectors.get_vecs_by_tokens([\".\"], lower_case_backup=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.加载数据、分词和词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "max_words = 200\n",
    "embed_len = 300\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    Y, X = list(zip(*batch))\n",
    "    X = [tokenizer(x) for x in X]\n",
    "    X = [tokens+[\"\"] * (max_words-len(tokens))  if len(tokens)<max_words else tokens[:max_words] for tokens in X]\n",
    "    X_tensor = torch.zeros(len(batch), max_words, embed_len)\n",
    "    Y_tensor = torch.zeros(len(batch),2)\n",
    "    for i, tokens in enumerate(X):\n",
    "        X_tensor[i] = global_vectors.get_vecs_by_tokens(tokens)\n",
    "\n",
    "    #for i, target in enumerate(Y):\n",
    "       # if (target==1):\n",
    "          #  Y_tensor[i] = torch.tensor([1,0])\n",
    "        #if (target==2):\n",
    "          #  Y_tensor[i] = torch.tensor([0,1])\n",
    "    return X_tensor,torch.tensor(Y)-1 #Y_tensor \n",
    "\n",
    "\n",
    "\n",
    "train_dataset, test_dataset  = torchtext.datasets.IMDB()\n",
    "\n",
    "train_dataset, test_dataset = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True,collate_fn=vectorize_batch)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=100,shuffle=False, collate_fn=vectorize_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.定义模型和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, features, num_hiddens,\n",
    "                 num_layers, **kwargs):\n",
    "        super(BiRNN, self).__init__(**kwargs)\n",
    "        # 将bidirectional设置为True以获取双向循环神经网络\n",
    "\n",
    "        self.encoder = nn.LSTM(features, num_hiddens, num_layers=num_layers,batch_first=True,\n",
    "                                bidirectional=True)\n",
    "        self.decoder = nn.Linear(4*num_hiddens, 2)\n",
    "    def forward(self, inputs):\n",
    "        #self.encoder.flatten_parameters()\n",
    "        outputs,_= self.encoder(inputs)\n",
    "        outs = self.decoder( torch.cat((outputs[:,0,:], outputs[:,-1,:]), dim=1))\n",
    "      \n",
    "        return  outs#outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=300\n",
    "num_layers=2\n",
    "num_hiddens=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiRNN(\n",
      "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (decoder): Linear(in_features=400, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BiRNN(features, num_hiddens, num_layers).to(device)\n",
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train dataset: 64 %\n",
      "Accuracy of the network on the test dataset: 63 %\n",
      "Accuracy of the network on the train dataset: 75 %\n",
      "Accuracy of the network on the test dataset: 75 %\n",
      "Accuracy of the network on the train dataset: 77 %\n",
      "Accuracy of the network on the test dataset: 75 %\n",
      "Accuracy of the network on the train dataset: 82 %\n",
      "Accuracy of the network on the test dataset: 82 %\n",
      "Accuracy of the network on the train dataset: 84 %\n",
      "Accuracy of the network on the test dataset: 83 %\n",
      "Accuracy of the network on the train dataset: 86 %\n",
      "Accuracy of the network on the test dataset: 84 %\n",
      "Accuracy of the network on the train dataset: 87 %\n",
      "Accuracy of the network on the test dataset: 85 %\n",
      "Accuracy of the network on the train dataset: 89 %\n",
      "Accuracy of the network on the test dataset: 85 %\n",
      "Accuracy of the network on the train dataset: 90 %\n",
      "Accuracy of the network on the test dataset: 84 %\n",
      "Accuracy of the network on the train dataset: 92 %\n",
      "Accuracy of the network on the test dataset: 85 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        _, predictions = torch.max(pred, 1)\n",
    "        '''\n",
    "        print(y)\n",
    "        print(pred)\n",
    "        print(_)\n",
    "        print(predictions)\n",
    "        '''\n",
    "        total += y.size(0)\n",
    "        correct += (predictions == y).sum().item()\n",
    "        loss = criterion(pred, y).requires_grad_(True)\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "    print(f'Accuracy of the network on the train dataset: {100 * correct // total} %')\n",
    "    train_acc=correct // total\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "            _, predictions = torch.max(pred, 1)\n",
    "    \n",
    "            total += y.size(0)\n",
    "            correct += (predictions == y).sum().item()\n",
    "    test_acc=correct // total\n",
    "    print(f'Accuracy of the network on the test dataset: {100 * correct // total} %')\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(net,  sequence):\n",
    "    \"\"\"预测文本序列的情感\"\"\"\n",
    "    sequence=tokenizer(sequence)\n",
    "    if len(sequence)<max_words :\n",
    "        sequence = sequence+[\"\"] * (max_words-len(sequence))   \n",
    "    else: \n",
    "        sequence[:max_words] \n",
    "    \n",
    "    sequence_tensor = torch.zeros(1, max_words, embed_len)\n",
    "    sequence_tensor = global_vectors.get_vecs_by_tokens(sequence)\n",
    "\n",
    "    pred=net(sequence_tensor.unsqueeze(0) .to(device))\n",
    "    _, predictions = torch.max(pred, 1)\n",
    "    \n",
    "\n",
    "    return 'positive' if predictions == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, 'this movie is so great')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, 'I love you')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, 'this movie is so bad')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
